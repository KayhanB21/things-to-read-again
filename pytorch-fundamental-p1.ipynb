{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data = [[1, 2], [3, 4]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]]) tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor(data)\n",
    "b = torch.from_numpy(np.array(data))\n",
    "print(a, b)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1],\n",
      "        [1, 1]], dtype=torch.int32) tensor([[0.4382, 0.1785],\n",
      "        [0.5894, 0.7074]])\n"
     ]
    }
   ],
   "source": [
    "c = torch.ones_like(b)\n",
    "d = torch.rand_like(b, dtype = torch.float)  #, dtype = torch.float is important\n",
    "print(c, d)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2]) torch.int32 cpu\n"
     ]
    }
   ],
   "source": [
    "c_shape = c.shape\n",
    "c_dtype = c.dtype\n",
    "c_device = c.device\n",
    "print(c_shape, c_dtype, c_device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.7316, 0.7914, 0.4970, 0.5719],\n",
      "         [0.6647, 0.4420, 0.8013, 0.5431],\n",
      "         [0.5945, 0.2923, 0.9739, 0.1604]],\n",
      "\n",
      "        [[0.3222, 0.4790, 0.0099, 0.8116],\n",
      "         [0.6835, 0.8644, 0.9121, 0.4993],\n",
      "         [0.6066, 0.7815, 0.8592, 0.7533]]]) tensor([[[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]]]) tensor([[[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "shape = (2, 3, 4)\n",
    "e = torch.rand(shape)\n",
    "f = torch.ones(shape)\n",
    "g = torch.zeros(shape)\n",
    "print(e, f, g)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.7316, 0.7914, 0.4970, 0.5719],\n",
      "         [0.6647, 0.4420, 0.8013, 0.5431],\n",
      "         [0.5945, 0.2923, 0.9739, 0.1604]],\n",
      "\n",
      "        [[0.3222, 0.4790, 0.0099, 0.8116],\n",
      "         [0.6835, 0.8644, 0.9121, 0.4993],\n",
      "         [0.6066, 0.7815, 0.8592, 0.7533]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    e = e.to('cuda')\n",
    "print(e)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7316, 0.7914, 0.4970, 0.5719],\n",
      "        [0.6647, 0.4420, 0.8013, 0.5431],\n",
      "        [0.5945, 0.2923, 0.9739, 0.1604]], device='cuda:0')\n",
      "tensor([[0.3222, 0.4790, 0.0099, 0.8116],\n",
      "        [0.6835, 0.8644, 0.9121, 0.4993],\n",
      "        [0.6066, 0.7815, 0.8592, 0.7533]], device='cuda:0')\n",
      "torch.Size([3, 4])\n",
      "torch.Size([3, 4])\n",
      "\n",
      "\n",
      "tensor([[0.7316, 0.7914, 0.4970, 0.5719],\n",
      "        [0.3222, 0.4790, 0.0099, 0.8116]], device='cuda:0')\n",
      "tensor([[0.7316, 0.6647, 0.5945],\n",
      "        [0.3222, 0.6835, 0.6066]], device='cuda:0')\n",
      "tensor([[0.6647, 0.4420, 0.8013, 0.5431],\n",
      "        [0.6835, 0.8644, 0.9121, 0.4993]], device='cuda:0')\n",
      "tensor([[0.7914, 0.4420, 0.2923],\n",
      "        [0.4790, 0.8644, 0.7815]], device='cuda:0')\n",
      "\n",
      "\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(e[0])\n",
    "print(e[1])\n",
    "print(e[0].shape)\n",
    "print(e[1].shape)\n",
    "print('\\n')\n",
    "\n",
    "print(e[:, 0])\n",
    "print(e[..., 0])\n",
    "print(e[:, 1])\n",
    "print(e[..., 1])\n",
    "print('\\n')\n",
    "\n",
    "print(e[:, 0].shape)\n",
    "print(e[..., 0].shape)\n",
    "print(e[:, 1].shape)\n",
    "print(e[..., 1].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7316, 0.3222], device='cuda:0')\n",
      "tensor([0.7316, 0.3222], device='cuda:0')\n",
      "tensor([0.6647, 0.6835], device='cuda:0')\n",
      "tensor([0.6647, 0.6835], device='cuda:0')\n",
      "\n",
      "\n",
      "torch.Size([2])\n",
      "torch.Size([2])\n",
      "torch.Size([2])\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "print(e[:, 0, 0])\n",
    "print(e[..., 0, 0])\n",
    "print(e[:, 1, 0])\n",
    "print(e[..., 1, 0])\n",
    "print('\\n')\n",
    "\n",
    "print(e[:, 0, 0].shape)\n",
    "print(e[..., 0, 0].shape)\n",
    "print(e[:, 1, 0].shape)\n",
    "print(e[..., 1, 0].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7316, 0.7914, 0.4970, 0.5719],\n",
      "        [0.6647, 0.4420, 0.8013, 0.5431],\n",
      "        [0.5945, 0.2923, 0.9739, 0.1604]], device='cuda:0')\n",
      "tensor([[0.7316, 0.7914, 0.4970, 0.5719],\n",
      "        [0.6647, 0.4420, 0.8013, 0.5431],\n",
      "        [0.5945, 0.2923, 0.9739, 0.1604]], device='cuda:0')\n",
      "tensor([[0.3222, 0.4790, 0.0099, 0.8116],\n",
      "        [0.6835, 0.8644, 0.9121, 0.4993],\n",
      "        [0.6066, 0.7815, 0.8592, 0.7533]], device='cuda:0')\n",
      "tensor([[0.3222, 0.4790, 0.0099, 0.8116],\n",
      "        [0.6835, 0.8644, 0.9121, 0.4993],\n",
      "        [0.6066, 0.7815, 0.8592, 0.7533]], device='cuda:0')\n",
      "\n",
      "\n",
      "torch.Size([3, 4])\n",
      "torch.Size([3, 4])\n",
      "torch.Size([3, 4])\n",
      "torch.Size([3, 4])\n",
      "\n",
      "\n",
      "tensor([0.7316, 0.6647, 0.5945], device='cuda:0')\n",
      "tensor([0.7316, 0.6647, 0.5945], device='cuda:0')\n",
      "tensor([0.3222, 0.6835, 0.6066], device='cuda:0')\n",
      "tensor([0.3222, 0.6835, 0.6066], device='cuda:0')\n",
      "\n",
      "\n",
      "torch.Size([2])\n",
      "torch.Size([2])\n",
      "torch.Size([2])\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "print(e[0, :])\n",
    "print(e[0, ...])\n",
    "print(e[1, :])\n",
    "print(e[1, ...])\n",
    "print('\\n')\n",
    "\n",
    "print(e[0, :].shape)\n",
    "print(e[0, ...].shape)\n",
    "print(e[1, :].shape)\n",
    "print(e[1, ...].shape)\n",
    "print('\\n')\n",
    "\n",
    "print(e[0, :, 0])\n",
    "print(e[0, ..., 0])\n",
    "print(e[1, :, 0])\n",
    "print(e[1, ..., 0])\n",
    "print('\\n')\n",
    "\n",
    "print(e[:, 0, 0].shape)\n",
    "print(e[..., 0, 0].shape)\n",
    "print(e[:, 1, 0].shape)\n",
    "print(e[..., 1, 0].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.7316, 0.7914, 0.4970, 0.5719],\n",
      "         [0.6647, 0.4420, 0.8013, 0.5431],\n",
      "         [0.5945, 0.2923, 0.9739, 0.1604]],\n",
      "\n",
      "        [[0.3222, 0.4790, 0.0099, 0.8116],\n",
      "         [0.6835, 0.8644, 0.9121, 0.4993],\n",
      "         [0.6066, 0.7815, 0.8592, 0.7533]],\n",
      "\n",
      "        [[0.7316, 0.7914, 0.4970, 0.5719],\n",
      "         [0.6647, 0.4420, 0.8013, 0.5431],\n",
      "         [0.5945, 0.2923, 0.9739, 0.1604]],\n",
      "\n",
      "        [[0.3222, 0.4790, 0.0099, 0.8116],\n",
      "         [0.6835, 0.8644, 0.9121, 0.4993],\n",
      "         [0.6066, 0.7815, 0.8592, 0.7533]]], device='cuda:0')\n",
      "torch.Size([4, 3, 4])\n",
      "tensor([[[0.7316, 0.7914, 0.4970, 0.5719],\n",
      "         [0.6647, 0.4420, 0.8013, 0.5431],\n",
      "         [0.5945, 0.2923, 0.9739, 0.1604],\n",
      "         [0.7316, 0.7914, 0.4970, 0.5719],\n",
      "         [0.6647, 0.4420, 0.8013, 0.5431],\n",
      "         [0.5945, 0.2923, 0.9739, 0.1604]],\n",
      "\n",
      "        [[0.3222, 0.4790, 0.0099, 0.8116],\n",
      "         [0.6835, 0.8644, 0.9121, 0.4993],\n",
      "         [0.6066, 0.7815, 0.8592, 0.7533],\n",
      "         [0.3222, 0.4790, 0.0099, 0.8116],\n",
      "         [0.6835, 0.8644, 0.9121, 0.4993],\n",
      "         [0.6066, 0.7815, 0.8592, 0.7533]]], device='cuda:0')\n",
      "torch.Size([2, 6, 4])\n",
      "tensor([[[0.7316, 0.7914, 0.4970, 0.5719, 0.7316, 0.7914, 0.4970, 0.5719],\n",
      "         [0.6647, 0.4420, 0.8013, 0.5431, 0.6647, 0.4420, 0.8013, 0.5431],\n",
      "         [0.5945, 0.2923, 0.9739, 0.1604, 0.5945, 0.2923, 0.9739, 0.1604]],\n",
      "\n",
      "        [[0.3222, 0.4790, 0.0099, 0.8116, 0.3222, 0.4790, 0.0099, 0.8116],\n",
      "         [0.6835, 0.8644, 0.9121, 0.4993, 0.6835, 0.8644, 0.9121, 0.4993],\n",
      "         [0.6066, 0.7815, 0.8592, 0.7533, 0.6066, 0.7815, 0.8592, 0.7533]]],\n",
      "       device='cuda:0')\n",
      "torch.Size([2, 3, 8])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-3, 2], but got 3)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-12-638eefeb8d75>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mh\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdim\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mh\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mh\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msep\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m\"\\n\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 7\u001B[1;33m \u001B[0mh\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdim\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m3\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      8\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mh\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mh\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msep\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m\"\\n\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mIndexError\u001B[0m: Dimension out of range (expected to be in range of [-3, 2], but got 3)"
     ]
    }
   ],
   "source": [
    "h = torch.cat([e, e], dim = 0)\n",
    "print(h, h.shape, sep = \"\\n\")\n",
    "h = torch.cat([e, e], dim = 1)\n",
    "print(h, h.shape, sep = \"\\n\")\n",
    "h = torch.cat([e, e], dim = 2)\n",
    "print(h, h.shape, sep = \"\\n\")\n",
    "h = torch.cat([e, e], dim = 3)\n",
    "print(h, h.shape, sep = \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 2])\n",
      "torch.Size([2, 3, 3])\n",
      "torch.Size([2, 3, 15])\n"
     ]
    }
   ],
   "source": [
    "print(e.T.shape)\n",
    "i = f @ torch.rand(2, 4, 3)\n",
    "print(i.shape, sep = '\\n')\n",
    "i = f @ torch.rand(2, 4, 15)\n",
    "print(i.shape, sep = '\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4, 5])\n",
      "torch.Size([2, 3, 4, 52])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (4) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-14-e2ed8a01eced>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mj\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrand\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m3\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m4\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m5\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m@\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrand\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m3\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m5\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m52\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mj\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msep\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m'\\n'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m \u001B[0mj\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrand\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m3\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m4\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m5\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m@\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrand\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m4\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m5\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m5\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mj\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msep\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m'\\n'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: The size of tensor a (3) must match the size of tensor b (4) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "j = torch.rand(2, 3, 4, 5) @ torch.rand(2, 3, 5, 5)\n",
    "print(j.shape, sep = '\\n')\n",
    "j = torch.rand(2, 3, 4, 5) @ torch.rand(2, 3, 5, 52)\n",
    "print(j.shape, sep = '\\n')\n",
    "j = torch.rand(2, 3, 4, 5) @ torch.rand(2, 4, 5, 5)\n",
    "print(j.shape, sep = '\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4, 5])\n",
      "torch.Size([2, 3, 4, 52])\n"
     ]
    }
   ],
   "source": [
    "j1 = torch.rand(2, 3, 4, 5)\n",
    "j2 = torch.rand(2, 3, 5, 5)\n",
    "j = j1.matmul(j2)\n",
    "print(j.shape, sep = '\\n')\n",
    "\n",
    "j1 = torch.rand(2, 3, 4, 5)\n",
    "j2 = torch.rand(2, 3, 5, 52)\n",
    "j = j1.matmul(j2)\n",
    "print(j.shape, sep = '\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3292)\n",
      "torch.Size([])\n",
      "torch.Size([3])\n",
      "torch.Size([10, 3])\n",
      "torch.Size([10, 3, 5])\n",
      "torch.Size([10, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "# vector x vector\n",
    "tensor1 = torch.randn(3)\n",
    "tensor2 = torch.randn(3)\n",
    "print(torch.matmul(tensor1, tensor2))\n",
    "print(torch.matmul(tensor1, tensor2).size())\n",
    "#torch.Size([])\n",
    "\n",
    "# matrix x vector\n",
    "tensor1 = torch.randn(3, 4)\n",
    "tensor2 = torch.randn(4)\n",
    "print(torch.matmul(tensor1, tensor2).size())\n",
    "#torch.Size([3])\n",
    "\n",
    "# batched matrix x broadcasted vector\n",
    "tensor1 = torch.randn(10, 3, 4)\n",
    "tensor2 = torch.randn(4)\n",
    "print(torch.matmul(tensor1, tensor2).size())\n",
    "#torch.Size([10, 3])\n",
    "\n",
    "# batched matrix x batched matrix\n",
    "tensor1 = torch.randn(10, 3, 4)\n",
    "tensor2 = torch.randn(10, 4, 5)\n",
    "print(torch.matmul(tensor1, tensor2).size())\n",
    "#torch.Size([10, 3, 5])\n",
    "\n",
    "# batched matrix x broadcasted matrix\n",
    "tensor1 = torch.randn(10, 3, 4)\n",
    "tensor2 = torch.randn(4, 5)\n",
    "print(torch.matmul(tensor1, tensor2).size())\n",
    "#torch.Size([10, 3, 5])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0883, 0.0027, 0.2335],\n",
      "        [0.0055, 0.2372, 0.2411]])\n",
      "torch.Size([2, 3])\n",
      "tensor([[0.0883, 0.0027, 0.2335],\n",
      "        [0.0055, 0.2372, 0.2411]])\n",
      "torch.Size([2, 3])\n",
      "tensor([[0.6077, 0.1134, 1.0892],\n",
      "        [0.1503, 1.1928, 0.9967]])\n",
      "torch.Size([2, 3])\n",
      "tensor([[-0.1272, -0.0469, -0.5024],\n",
      "        [ 0.0215, -0.6884,  0.1698]])\n",
      "torch.Size([2, 3])\n",
      "tensor([[0.6538, 0.4150, 0.3687],\n",
      "        [1.3347, 0.2681, 1.4108]])\n",
      "torch.Size([2, 3])\n",
      "tensor([[0., 0., 0.],\n",
      "        [1., 0., 1.]])\n",
      "torch.Size([2, 3])\n",
      "tensor([[0., 0., 0.],\n",
      "        [1., 0., 1.]])\n",
      "torch.Size([2, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Keyha\\.virtualenvs\\things-to-read-again-E7o4ITPW\\lib\\site-packages\\torch\\_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  ..\\aten\\src\\ATen\\native\\BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (4) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-17-9e8ae8453e5d>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[0mj2\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrand\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m4\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mj\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msep\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m'\\n'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 18\u001B[1;33m \u001B[0mj\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mj1\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mj2\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     19\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: The size of tensor a (3) must match the size of tensor b (4) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "j1 = torch.rand(2, 3)\n",
    "j2 = torch.rand(2, 3)\n",
    "j = j1.mul(j2)\n",
    "print(j, j.shape, sep = '\\n')\n",
    "j = j1 * j2\n",
    "print(j, j.shape, sep = '\\n')\n",
    "j = j1 + j2\n",
    "print(j, j.shape, sep = '\\n')\n",
    "j = j1 - j2\n",
    "print(j, j.shape, sep = '\\n')\n",
    "j = j1 / j2\n",
    "print(j, j.shape, sep = '\\n')\n",
    "j = j1 // j2\n",
    "print(j, j.shape, sep = '\\n')\n",
    "j1 = torch.rand(2, 3)\n",
    "j2 = torch.rand(2, 4)\n",
    "print(j, j.shape, sep = '\\n')\n",
    "j = j1 * j2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(24.) <class 'torch.Tensor'>\n",
      "24.0 <class 'float'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-18-32415c90ebab>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0ma\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0ma\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ma\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ma\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m \u001B[0ma\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ma\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ma\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "a = f.sum()\n",
    "print(a, type(a))\n",
    "a = a.item()\n",
    "print(a, type(a))\n",
    "a = f.item()\n",
    "print(a, type(a))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]]])\n",
      "\n",
      "\n",
      "tensor([[[6., 6., 6., 6.],\n",
      "         [6., 6., 6., 6.],\n",
      "         [6., 6., 6., 6.]],\n",
      "\n",
      "        [[6., 6., 6., 6.],\n",
      "         [6., 6., 6., 6.],\n",
      "         [6., 6., 6., 6.]]])\n",
      "\n",
      "\n",
      "tensor([[[6., 6., 6., 6.],\n",
      "         [6., 6., 6., 6.],\n",
      "         [6., 6., 6., 6.]],\n",
      "\n",
      "        [[6., 6., 6., 6.],\n",
      "         [6., 6., 6., 6.],\n",
      "         [6., 6., 6., 6.]]])\n",
      "\n",
      "\n",
      "tensor([[[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]]])\n",
      "\n",
      "\n",
      "tensor([[[6., 6., 6., 6.],\n",
      "         [6., 6., 6., 6.],\n",
      "         [6., 6., 6., 6.]],\n",
      "\n",
      "        [[6., 6., 6., 6.],\n",
      "         [6., 6., 6., 6.],\n",
      "         [6., 6., 6., 6.]]])\n",
      "tensor([[[6., 6., 6., 6.],\n",
      "         [6., 6., 6., 6.],\n",
      "         [6., 6., 6., 6.]],\n",
      "\n",
      "        [[6., 6., 6., 6.],\n",
      "         [6., 6., 6., 6.],\n",
      "         [6., 6., 6., 6.]]])\n"
     ]
    }
   ],
   "source": [
    "print(f)\n",
    "print('\\n')\n",
    "print(f + 5)\n",
    "print('\\n')\n",
    "print(f.add(5))\n",
    "print('\\n')\n",
    "print(f)\n",
    "print('\\n')\n",
    "print(f.add_(5))\n",
    "print(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[6. 6. 6. 6.]\n",
      "  [6. 6. 6. 6.]\n",
      "  [6. 6. 6. 6.]]\n",
      "\n",
      " [[6. 6. 6. 6.]\n",
      "  [6. 6. 6. 6.]\n",
      "  [6. 6. 6. 6.]]] <class 'numpy.ndarray'>\n",
      "tensor([[[6., 6., 6., 6.],\n",
      "         [6., 6., 6., 6.],\n",
      "         [6., 6., 6., 6.]],\n",
      "\n",
      "        [[6., 6., 6., 6.],\n",
      "         [6., 6., 6., 6.],\n",
      "         [6., 6., 6., 6.]]])\n",
      "[[[1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]]] tensor([[[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "t = f.numpy()\n",
    "print(t, type(t))\n",
    "print(f)\n",
    "f.add_(-5)\n",
    "print(t, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [
     "#coding=utf-8"
    ],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}